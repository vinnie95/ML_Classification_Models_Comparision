{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "## Mobile Price Classification - ML Assignment 2\n",
    "\n",
    "This notebook implements **Logistic Regression** for mobile price classification.\n",
    "\n",
    "### Dataset:\n",
    "- 20 features (mobile specifications)\n",
    "- 2000 samples\n",
    "- 4 classes (price ranges: 0, 1, 2, 3)\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- Accuracy\n",
    "- AUC Score\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- MCC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ All libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print('Loading dataset...')\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "print(f'✓ Dataset loaded: {df.shape}')\n",
    "print(f'  Features: {df.shape[1] - 1}')\n",
    "print(f'  Samples: {df.shape[0]}')\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print('Target Distribution:')\n",
    "print(df['price_range'].value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['price_range'].value_counts().sort_index().plot(\n",
    "    kind='bar',\n",
    "    color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
    ")\n",
    "plt.title('Price Range Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Price Range')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1, 2, 3], ['Low', 'Medium', 'High', 'Very High'], rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('price_range', axis=1)\n",
    "y = df['price_range']\n",
    "\n",
    "# Split data (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}')\n",
    "print(f'Testing samples: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Required for this model)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('✓ Features scaled using StandardScaler')\n",
    "\n",
    "# Save scaler\n",
    "with open('../scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print('✓ Scaler saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print('Training model...')\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('✓ Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Get probabilities if available\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "else:\n",
    "    y_pred_proba = None\n",
    "\n",
    "print('✓ Predictions completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# AUC Score\n",
    "if y_pred_proba is not None:\n",
    "    y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "else:\n",
    "    auc = 0.0\n",
    "\n",
    "# Display\n",
    "print('='*60)\n",
    "print('EVALUATION METRICS - LOGISTIC REGRESSION')\n",
    "print('='*60)\n",
    "print(f'Accuracy:  {accuracy:.4f}')\n",
    "print(f'AUC Score: {auc:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall:    {recall:.4f}')\n",
    "print(f'F1 Score:  {f1:.4f}')\n",
    "print(f'MCC Score: {mcc:.4f}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low', 'Medium', 'High', 'Very High'],\n",
    "            yticklabels=['Low', 'Medium', 'High', 'Very High'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print('Classification Report:')\n",
    "print('='*60)\n",
    "report = classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=['Low', 'Medium', 'High', 'Very High'],\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': np.abs(model.coef_[0])\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print('Top 10 Features:')\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "top10 = feature_importance.head(10)\n",
    "plt.barh(range(len(top10)), top10['Coefficient'])\n",
    "plt.yticks(range(len(top10)), top10['Feature'])\n",
    "plt.xlabel('Absolute Coefficient')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and results\n",
    "with open('../logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('✓ Model saved to: logistic_regression.pkl')\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame([{\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Accuracy': round(accuracy, 4),\n",
    "    'AUC': round(auc, 4),\n",
    "    'Precision': round(precision, 4),\n",
    "    'Recall': round(recall, 4),\n",
    "    'F1': round(f1, 4),\n",
    "    'MCC': round(mcc, 4)\n",
    "}])\n",
    "\n",
    "results_df.to_csv('../logistic_regression_results.csv', index=False)\n",
    "print('✓ Results saved')\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Logistic Regression Model Results:\n",
    "\n",
    "**Performance Metrics:**\n",
    "- Accuracy: See above\n",
    "- AUC Score: See above\n",
    "- F1 Score: See above\n",
    "\n",
    "**Model Saved:**\n",
    "- Model file: `logistic_regression.pkl`\n",
    "- Results: `logistic_regression_results.csv`\n",
    "\n",
    "**Next Steps:**\n",
    "- Run other model notebooks\n",
    "- Compare all results\n",
    "- Deploy best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
